{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioMED Gradio APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import gradio as gr\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(file_path):\n",
    "    \"\"\"Check valid for image file extensions\"\"\"\n",
    "    image_extensions = [\n",
    "        \".jpeg\",\n",
    "        \".jpg\",\n",
    "        \".png\",\n",
    "        \".gif\",\n",
    "        \".bmp\",\n",
    "        \".tiff\",\n",
    "        \".svg\",\n",
    "        \".pdf\",\n",
    "    ]\n",
    "    return any(file_path.lower().endswith(ext) for ext in image_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Function to encode the image\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_conversation_history(chat_history):\n",
    "    \"\"\"Build conversation history\"\"\"\n",
    "    messages = []\n",
    "    previous_role = None\n",
    "    combined_content = []\n",
    "\n",
    "    for history in chat_history:\n",
    "        role = history[\"role\"]\n",
    "        content = history[\"content\"]\n",
    "\n",
    "        if isinstance(content, tuple) and len(content) > 0:\n",
    "            content = content[0]\n",
    "\n",
    "        if role == \"user\":\n",
    "            if isinstance(content, str) and is_image(content):\n",
    "                base64_file = encode_image(content)\n",
    "                part = {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_file}\"},\n",
    "                }\n",
    "            else:\n",
    "                part = {\"type\": \"text\", \"text\": content}\n",
    "\n",
    "            if role == previous_role:\n",
    "                combined_content.append(part)\n",
    "            else:\n",
    "                # Only append previous combined content if previous role was user\n",
    "                if previous_role == \"user\" and combined_content:\n",
    "                    messages.append(\n",
    "                        {\"role\": previous_role, \"content\": combined_content}\n",
    "                    )\n",
    "                combined_content = [part]\n",
    "        else:\n",
    "            # Handle non-user role\n",
    "            if previous_role == \"user\" and combined_content:\n",
    "                messages.append({\"role\": \"user\", \"content\": combined_content})\n",
    "                combined_content = []\n",
    "            messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "        previous_role = role\n",
    "\n",
    "    # Add any remaining combined content after loop ends\n",
    "    if combined_content:\n",
    "        messages.append({\"role\": previous_role, \"content\": combined_content})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_latest_conversation(latest_message, messages):\n",
    "    \"\"\"Build latest conversation-\n",
    "    # Add new user message\n",
    "    # Extract the text and files\"\"\"\n",
    "    text = latest_message[\"text\"]\n",
    "    files = latest_message[\"files\"]\n",
    "\n",
    "    input_messages = []\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            base64_file = encode_image(file)\n",
    "            input_messages.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_file}\"},\n",
    "                }\n",
    "            )\n",
    "\n",
    "        input_messages.append({\"type\": \"text\", \"text\": text})\n",
    "        messages.append({\"role\": \"user\", \"content\": input_messages})\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": text})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, chat_history, api_key):\n",
    "    if not api_key.strip():\n",
    "        return \"âš ï¸ Please enter your GROQ API key first!\"\n",
    "\n",
    "    try:\n",
    "        client = Groq(api_key=api_key.strip())\n",
    "\n",
    "        # Build conversation history\n",
    "        messages = construct_conversation_history(chat_history)\n",
    "\n",
    "        # Build latest conversation\n",
    "        messages = construct_latest_conversation(message, messages)\n",
    "\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024,\n",
    "        )\n",
    "\n",
    "        bot_message = chat_completion.choices[0].message.content\n",
    "        return bot_message\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with gr.Blocks() as demo:\n",
    "        with gr.Accordion(\"Enter your Groq key!\", open=False):\n",
    "            api_key = gr.Textbox(\n",
    "                label=\"GROQ API Key\",\n",
    "                placeholder=\"Enter your key here...\",\n",
    "                type=\"password\",\n",
    "            )\n",
    "\n",
    "        with gr.Accordion(\"BioMEDICAL VisionLM AI Tool\", open=True):\n",
    "            gr.ChatInterface(\n",
    "                title=\"BioMEDâš•ï¸\",\n",
    "                description=\"> ðŸš¨ This application is designed as a comprehensive AI tool for medical analysis, leveraging advanced multimodal capabilities to assist healthcare professionals and potentially extend access to underserved communities.\",\n",
    "                theme=\"soft\",\n",
    "                show_progress=\"full\",\n",
    "                fill_height=True,\n",
    "                fill_width=True,\n",
    "                fn=chat,\n",
    "                additional_inputs=api_key,\n",
    "                type=\"messages\",\n",
    "                multimodal=True,\n",
    "                examples=[],\n",
    "            )\n",
    "\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
