{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioMED Image-Text-to-Text microsoft/llava-med-v1.5-mistral-7b\n",
    "\n",
    "[microsoft/llava-med-v1.5-mistral-7b](https://huggingface.co/microsoft/llava-med-v1.5-mistral-7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach-1 using HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/llava-med-v1.5-mistral-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True, device_map=\"auto\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 23:49:49,623] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, LlamaConfig \n",
    "from llava.model.language_model.llava_llama import LlavaLlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlavaConfig(LlamaConfig):\n",
    "    model_type = \"llava\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thivav/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava_mistral to instantiate a model of type llava. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "AutoConfig.register(\"llava\", LlavaConfig)\n",
    "model = LlavaLlamaForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach-2 using llava-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llava.constants import DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX\n",
    "from llava.conversation import SeparatorStyle, conv_templates\n",
    "from llava.mm_utils import (\n",
    "    KeywordsStoppingCriteria,\n",
    "    get_model_name_from_path,\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    ")\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_torch_init()\n",
    "MODEL = \"microsoft/llava-med-v1.5-mistral-7b\"\n",
    "model_name = get_model_name_from_path(MODEL)\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path=MODEL, model_base=None, model_name=model_name, load_4bit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/master_data/brain_xray.jpeg\"\n",
    "image = Image.open(image_file).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    args = {\"image_aspect_ratio\": \"pad\"}\n",
    "    image_tensor = process_images([image], image_processor, args)\n",
    "    return image_tensor.to(model.device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image = process_image(image)\n",
    "type(processed_image), processed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_MODE = \"llava_v0\"\n",
    "\n",
    "def create_prompt(prompt: str):\n",
    "    conv = conv_templates[CONV_MODE].copy()\n",
    "    roles = conv.roles\n",
    "    prompt = DEFAULT_IMAGE_TOKEN + \"\\n\" + prompt\n",
    "    conv.append_message(roles[0], prompt)\n",
    "    conv.append_message(roles[1], None)\n",
    "    return conv.get_prompt(), conv\n",
    "\n",
    "prompt, conv = create_prompt(\"What type of imaging does this represent?\")\n",
    "print(\"prompt:\", prompt, \"\\nconv:\", conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_image(image: Image, prompt: str):\n",
    "    print(\"I got his prompt:\", prompt)\n",
    "    \n",
    "    image_tensor = process_image(image)\n",
    "    prompt, conv = create_prompt(prompt)\n",
    "    input_ids = (\n",
    "        tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\")\n",
    "        .unsqueeze(0)\n",
    "        .to(model.device)\n",
    "    )\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    stopping_criteria = KeywordsStoppingCriteria(\n",
    "        keywords=[stop_str], tokenizer=tokenizer, input_ids=input_ids\n",
    "    )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            images=image_tensor,\n",
    "            do_sample=True,\n",
    "            temperature=0.01,\n",
    "            max_new_tokens=512,\n",
    "            use_cache=True,\n",
    "            stopping_criteria=[stopping_criteria],\n",
    "        )\n",
    "        print(\"decoded output_ids\", tokenizer.decode(output_ids[0, input_ids.shape[1]:])) #input_ids.shape[1] :\n",
    "    return tokenizer.decode(\n",
    "        output_ids[0, input_ids.shape[1] :], skip_special_tokens=True\n",
    "    ).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1\n",
    "# query = \"a photography of\"\n",
    "\n",
    "## 2\n",
    "query = \"\"\"Analyze the provided photograph and perform the following tasks:\n",
    "            1. Identification: Describe the key features or abnormalities visible in the image.\n",
    "            2. Prognosis: Suggest potential implications or diagnoses based on the identified features (if applicable).\n",
    "            3. Description: Provide a detailed summary of the observed structures, focusing on medical relevance.\"\"\"\n",
    "\n",
    "## 3\n",
    "# query = \"do the prognosis\"\n",
    "\n",
    "## 4\n",
    "# query = \"What type of imaging does this represent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ask_image(image, query)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
