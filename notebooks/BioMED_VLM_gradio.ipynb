{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(message, history, api_key):\n",
    "    num_images = len(message[\"files\"])\n",
    "    total_images = 0\n",
    "    for message in history:\n",
    "        if isinstance(message[\"content\"], tuple):\n",
    "            total_images += 1\n",
    "    return f\"You just uploaded {num_images} images, total uploaded: {total_images+num_images}, api_key: {api_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A description for the interface; if provided, appears above the chatbot and beneath the title in regular font. Accepts Markdown and HTML content.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    title=\"BioMED\",\n",
    "    description=\"## A description for the interface; if provided, appears above the chatbot and beneath the title in regular font. Accepts Markdown and HTML content.\",\n",
    "    theme=\"gradio/monochrome\",\n",
    "    show_progress=\"full\",\n",
    "    fill_height=True,\n",
    "    fill_width=True,\n",
    "    # save_history=True,\n",
    "    fn=count_images, \n",
    "    type=\"messages\", \n",
    "    # examples=[\n",
    "    #     {\"text\": \"No files\", \"files\": []}\n",
    "    # ], \n",
    "    multimodal=True,\n",
    "    textbox=gr.MultimodalTextbox(file_count=\"multiple\", file_types=[\"image\", \".pdf\"], sources=[\"upload\"], interactive=True),\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    title=\"BioMED\",\n",
    "    description=\"## A description for the interface; if provided, appears above the chatbot and beneath the title in regular font. Accepts Markdown and HTML content.\",\n",
    "    theme=\"gradio/monochrome\",\n",
    "    show_progress=\"full\",\n",
    "    fill_height=True,\n",
    "    fill_width=True,\n",
    "    # save_history=True,\n",
    "    fn=count_images, \n",
    "    type=\"messages\", \n",
    "    # examples=[\n",
    "    #     {\"text\": \"No files\", \"files\": []}\n",
    "    # ], \n",
    "    multimodal=True,\n",
    "    textbox=gr.MultimodalTextbox(file_count=\"multiple\", file_types=[\"image\", \".pdf\"], sources=[\"upload\"], interactive=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "model = \"llama3-70b-8192\"  # Example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=0.7,  # Control randomness (0=deterministic, 1=creative)\n",
    "        max_tokens=1024    # Limit response length\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def stream_chat(message, history):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        model=model,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    partial_response = \"\"\n",
    "    for chunk in response:\n",
    "        partial_response += chunk.choices[0].delta.content\n",
    "        yield partial_response  # Stream tokens incrementally:cite[5]:cite[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/vault/devhub/medllm_researchhub/.venv/lib/python3.13/site-packages/gradio/components/chatbot.py:288: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat,  # Replace with `stream_chat` for streaming\n",
    "    title=\"Groq-Powered Chatbot\",\n",
    "    description=\"Ask me anything!\",\n",
    "    examples=[\"Explain quantum physics\", \"Write a poem about AI\"],\n",
    "    theme=\"soft\",\n",
    "    # retry_btn=None  # Customize UI components:cite[1]:cite[7]\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/vault/devhub/medllm_researchhub/.venv/lib/python3.13/site-packages/gradio/components/chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from groq import Groq\n",
    "\n",
    "def respond(message, chat_history, api_key):\n",
    "    if not api_key.strip():\n",
    "        return chat_history + [(message, \"⚠️ Please enter your GROQ API key first!\")]\n",
    "    \n",
    "    try:\n",
    "        client = Groq(api_key=api_key.strip())\n",
    "        \n",
    "        # Build conversation history\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "        for user_msg, bot_msg in chat_history:\n",
    "            messages.extend([\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "                {\"role\": \"assistant\", \"content\": bot_msg}\n",
    "            ])\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        # Get response\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        bot_message = response.choices[0].message.content\n",
    "        return chat_history + [(message, bot_message)]\n",
    "    \n",
    "    except Exception as e:\n",
    "        return chat_history + [(message, f\"❌ Error: {str(e)}\")]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Groq Chatbot - Enter API Key to Start\")\n",
    "    \n",
    "    # API Key input (always visible)\n",
    "    api_key = gr.Textbox(\n",
    "        label=\"GROQ API Key\",\n",
    "        placeholder=\"Enter your key here...\",\n",
    "        type=\"password\"\n",
    "    )\n",
    "    \n",
    "    # Chat interface\n",
    "    chatbot = gr.Chatbot(height=400)\n",
    "    msg = gr.Textbox(label=\"Your Message\")\n",
    "    clear_btn = gr.ClearButton([msg, chatbot, api_key])\n",
    "    \n",
    "    # Chat handling\n",
    "    msg.submit(\n",
    "        respond,\n",
    "        [msg, chatbot, api_key],\n",
    "        [chatbot],\n",
    "        queue=False\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from groq import Groq\n",
    "\n",
    "def respond(message, chat_history, api_key):\n",
    "    if not api_key.strip():\n",
    "        return chat_history + [(message, \"⚠️ Please enter your GROQ API key first!\")]\n",
    "    \n",
    "    try:\n",
    "        client = Groq(api_key=api_key.strip())\n",
    "        \n",
    "        # Build conversation history\n",
    "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "        for user_msg, bot_msg in chat_history:\n",
    "            messages.extend([\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "                {\"role\": \"assistant\", \"content\": bot_msg}\n",
    "            ])\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "        # Get response\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama3-70b-8192\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        \n",
    "        bot_message = response.choices[0].message.content\n",
    "        return chat_history + [(message, bot_message)]\n",
    "    \n",
    "    except Exception as e:\n",
    "        return chat_history + [(message, f\"❌ Error: {str(e)}\")]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Groq Chatbot - Enter API Key to Start\")\n",
    "    \n",
    "    # API Key input (always visible)\n",
    "    api_key = gr.Textbox(\n",
    "        label=\"GROQ API Key\",\n",
    "        placeholder=\"Enter your key here...\",\n",
    "        type=\"password\"\n",
    "    )\n",
    "    \n",
    "    # # Chat interface\n",
    "    # chatbot = gr.Chatbot(height=400)\n",
    "    # msg = gr.Textbox(label=\"Your Message\")\n",
    "    # clear_btn = gr.ClearButton([msg, chatbot, api_key])\n",
    "    \n",
    "    # # Chat handling\n",
    "    # msg.submit(\n",
    "    #     respond,\n",
    "    #     [msg, chatbot, api_key],\n",
    "    #     [chatbot],\n",
    "    #     queue=False\n",
    "    # )\n",
    "\n",
    "    # Chat interface\n",
    "    gr.ChatInterface(\n",
    "        title=\"BioMED\",\n",
    "        description=\"## A description for the interface; if provided, appears above the chatbot and beneath the title in regular font. Accepts Markdown and HTML content.\",\n",
    "        theme=\"gradio/monochrome\",\n",
    "        show_progress=\"full\",\n",
    "        fill_height=True,\n",
    "        fill_width=True,\n",
    "        # save_history=True,\n",
    "        fn=count_images,\n",
    "        additional_inputs=api_key, \n",
    "        type=\"messages\", \n",
    "        # examples=[\n",
    "        #     {\"text\": \"No files\", \"files\": []}\n",
    "        # ], \n",
    "        multimodal=True,\n",
    "        # textbox=gr.MultimodalTextbox(file_count=\"multiple\", file_types=[\"image\", \".pdf\"], sources=[\"upload\"], interactive=True),\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/vault/devhub/medllm_researchhub/.venv/lib/python3.13/site-packages/gradio/components/chatbot.py:288: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* Running on public URL: https://c22249eb1cb3112c8e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c22249eb1cb3112c8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from groq import Groq\n",
    "\n",
    "def count_images(message, history, api_key):\n",
    "    # Extract files from current message\n",
    "    current_files = message.get(\"files\", [])\n",
    "    num_images = len(current_files)\n",
    "    \n",
    "    # Count all files in history\n",
    "    total_files = 0\n",
    "    for entry in history:\n",
    "        if isinstance(entry, list) and len(entry) >= 1:\n",
    "            user_message = entry[0]\n",
    "            if isinstance(user_message, dict) and \"files\" in user_message:\n",
    "                total_files += len(user_message[\"files\"])\n",
    "    \n",
    "    return (f\"You just uploaded {num_images} files. \"\n",
    "            f\"Total uploaded files: {total_files + num_images}, \"\n",
    "            f\"API key: {api_key[:5]}...\")  # Show partial key for security\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Groq Chatbot - Enter API Key to Start\")\n",
    "    \n",
    "    # API Key input (always visible)\n",
    "    api_key = gr.Textbox(\n",
    "        label=\"GROQ API Key\",\n",
    "        placeholder=\"Enter your key here...\",\n",
    "        type=\"password\"\n",
    "    )\n",
    "    \n",
    "    # Chat interface with enhanced file upload settings\n",
    "    gr.ChatInterface(\n",
    "        title=\"BioMED\",\n",
    "        description=\"Upload multiple PDFs and images (PNG, JPG)\",\n",
    "        theme=\"gradio/monochrome\",\n",
    "        show_progress=\"full\",\n",
    "        fill_height=True,\n",
    "        fn=count_images,\n",
    "        additional_inputs=api_key,\n",
    "        multimodal=gr.MultimodalTextbox(\n",
    "            file_count=\"multiple\",\n",
    "            file_types=[\".pdf\", \".png\", \".jpg\", \".jpeg\"],\n",
    "            # upload_btn=\"📁 Upload\",\n",
    "            placeholder=\"Type message or upload files...\",\n",
    "        ),\n",
    "        examples=[\n",
    "            [\"Analyze these reports\", [\"report1.pdf\", \"xray.jpg\"]],\n",
    "            [\"Compare these images\", [\"image1.png\", \"image2.jpeg\"]]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/vault/devhub/medllm_researchhub/.venv/lib/python3.13/site-packages/gradio/components/chatbot.py:288: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "* Running on public URL: https://3c45c5365834149de6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3c45c5365834149de6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from groq import Groq\n",
    "\n",
    "def process_message(message, history, api_key):\n",
    "    # Handle files and message\n",
    "    files = message.get(\"files\", [])\n",
    "    text = message.get(\"text\", \"\")\n",
    "    \n",
    "    # Process files (example implementation)\n",
    "    file_info = []\n",
    "    for file in files:\n",
    "        file_type = \"PDF\" if file.name.endswith(\".pdf\") else \"Image\"\n",
    "        file_info.append(f\"{file_type} uploaded: {file.name.split('/')[-1]}\")\n",
    "    \n",
    "    response = f\"API key: {api_key[:5]}...\\n\" if api_key else \"No API key entered\\n\"\n",
    "    response += f\"Message: {text}\\n\"\n",
    "    response += \"Files:\\n\" + \"\\n\".join(file_info) if file_info else \"No files uploaded\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## BioMED Chatbot\")\n",
    "    \n",
    "    # API Key input - separate from chat interface\n",
    "    api_key = gr.Textbox(\n",
    "        label=\"GROQ API Key\",\n",
    "        placeholder=\"Enter your key here...\",\n",
    "        type=\"password\",\n",
    "        container=False\n",
    "    )\n",
    "    \n",
    "    # Chat interface with separate multimodal upload\n",
    "    gr.ChatInterface(\n",
    "        process_message,\n",
    "        additional_inputs=api_key,\n",
    "        multimodal=gr.MultimodalTextbox(\n",
    "            file_count=\"multiple\",\n",
    "            file_types=[\".pdf\", \".png\", \".jpg\", \".jpeg\"],\n",
    "            # upload_btn=\"📁 Upload Files\",\n",
    "            show_label=False,\n",
    "            placeholder=\"Type your message or upload files here...\",\n",
    "        ),\n",
    "        title=\"BioMED\",\n",
    "        description=\"Upload multiple PDFs and images (PNG/JPG/JPEG)\",\n",
    "        theme=\"gradio/monochrome\",\n",
    "        examples=[\n",
    "            [\"Analyze these reports\", [\"report1.pdf\", \"xray.jpg\"]],\n",
    "            [\"Compare these images\", [\"image1.png\", \"image2.jpeg\"]]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
